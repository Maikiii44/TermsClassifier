# â™» Terms Classifier

This repo contains code to train a model that classifies terms into Nice Classes.  
It uses PEFT to finetune embedding models. The repo implements PEFT methods with  
PyTorch Lightning.

## âš™ï¸ Installation & Setup

To install it you just need to run the following command in an environment with Python
3.12 or higher:

```shell
poetry install
```

**ğŸ“Œ _NOTES:_**

* The current Poetry toml respect the nomenclature of the versions above `2.0.0`
* I would recommend to downgrade the major version, seems easier to use.

When in development mode, it is recommended to install all the extra dependencies
by running:

```shell
poetry install --all-extras
```

In case you want to update the dependencies once installed the first version, you just
need to:

```shell
poetry update
```

And the `poetry.lock` file will be updated too, if applicable.

To get help how to run the CLI you will need to run the following command:

```shell
poetry run terms --help
```

Finally, in order to run the static code analysis checks you should use the following
set of commands once installed:

```shell
poetry run ruff --fix terms
poetry run mypy termss
```

## ğŸ” Package Lifecycle

First of all you'll need to install the current Python package with `poetry install --all-extras` so
that the `poetry.lock` file will be generated and a new virtual environment will be created.

Once the Python package is installed, you can do code-changes and use it via the CLI with
`poetry run terms --help` or just by running Python with `poetry run python`
so as to open a Python terminal in the created virtual environment.

In case you add/update the dependencies in `pyproject.toml` you'll need to run `poetry lock --no-update`
to update the `poetry.lock` file. After that, execute `poetry install --all-extras` to update and install
the packages that are needed.

Also, you need to remember to commit and push the changes in `poetry.lock` usually with the following
commit message "ğŸ“¦ Run \`poetry update\`".

## ğŸ“ Project Structure

```text
ğŸ“‚ Wipo
â”œâ”€â”€ ğŸ“‚ docs/               - auto-generated and hand-written documentation
â”œâ”€â”€ ğŸ“‚ configurations/     - project configuration files (both checked-in and auto-generated)
â”œâ”€â”€ ğŸ“‚ data/               - raw, interim, and processed datasets
â”œâ”€â”€ ğŸ“‚ notebooks/          - exploratory notebooks, reports, and visual analyses
â”œâ”€â”€ ğŸ“‚ src/                - source code root
â”‚   â”œâ”€â”€ ğŸ“‚ app/             - FastAPI application for serving inference APIs
â”‚   â”‚   â””â”€â”€ ğŸ __init__.py
â”‚   â””â”€â”€ ğŸ“‚ terms/      - core logic for classification, preprocessing, and LLM handling
â”‚       â”œâ”€â”€ ğŸ“‚ model/               - training-related code for the classifier
â”‚       â”‚   â”œâ”€â”€ ğŸ data.py          - data preparation and loading logic
â”‚       â”‚   â”œâ”€â”€ ğŸ metrics.py       - metric definitions and evaluations
â”‚       â”‚   â”œâ”€â”€ ğŸ module.py        - PyTorch Lightning module definition
â”‚       â”‚   â””â”€â”€ ğŸ train.py         - training entry point and logic
â”‚       â”œâ”€â”€ ğŸ __init__.py
â”‚       â”œâ”€â”€ ğŸ cli.py               - command-line interface entry-point (`python -m trademarks.cli`)
â”‚       â”œâ”€â”€ ğŸ config.py            - global configuration dataclass & loaders
â”‚       â”œâ”€â”€ ğŸ constants.py         - package-wide constant values
â”‚       â”œâ”€â”€ ğŸ logs.py              - unified logging configuration & helpers
â”‚       â”œâ”€â”€ ğŸ preprocess.py        - data pre-processing for training & inference
â”‚       â”œâ”€â”€ ğŸ pipeline.py          - end-to-end inference pipeline orchestrator
â”‚       â”œâ”€â”€ ğŸ schemas.py           - Pandera models and typing schemas
â”‚       â””â”€â”€ ğŸ utils.py             - assorted helper functions
â””â”€â”€ ğŸ“‚ tests/              - unit & integration tests (mirrors package structure)
```


### ğŸ§  Train the Model

One of the main command lines is the train command. To see how to use it
run the following:

```bash
poetry run terms --help
```

#### How to Use the Command for Generating Proposals for Testing

Here's an example of how to use the command to generate proposals for testing:

```bash
poetry run terms 
    --data-filepath "./data/data_small.parquet" 
    --pretrained-model-name "BAAI/bge-small-en-v1.5" 
    --lora-config-path "./configurations/lora_config.yaml"
```


## ğŸ“Š MLflow Tracking

Training metrics are stored locally in the `mlruns` folder at the root of the project.  
You can change this path in `train.py` under the `logger` settings.

To launch the MLflow UI locally (if you haven't changed the default paths),  
run the following command in your virtual environment:

```bash
mlflow ui --backend-store-uri ./mlruns --port 5001
```